
Name-it: webgame
================
reuse the image-tagging-as-a-game idea but with topic model
user1 and user2 get presented with words from some topic
and they have to give a "short description" in up to three 
words that best sums up the words they see.
(weight the word font sizes by their probability)

if the users enter something that matches then "tag" is accepted,
if not they keep entering new descriptions…

if nothing good comes out … maybe the topic model wasn't so good 
and we should re-run the algorithm OR simply this is one of the
mixed topics

quick test on arXiv topics on physics people?
mass-email after the conference....





Usage scenario
==============

To redo the arXiv experiments, this is what I would do:
 - create a dc = DirectoryListDC(["data/"], cachedir="data_dc_store") 
        --> walks the tree creates a Document for each pdf
        --> for each id = filepath
 - run dc.wordcounts
        --> for each pdf, it will convert to text do a wc 
        --> store output in cachedir
 - vocab=Vocab( dc, maxwords=10000, filters=["stopwords", "3lettermin"], minoccur=3 ...
        --> will go through entire dc and make an aggregate wordcount list
        --> 
        --> applies filters
        --> stores somewhere?
 - Create the topic model
    tm = TopicModel()
    tm.fromDC(documents=dc, T=30, rundir="runs/run300", name?, vocab=vocab)
        --> create rundir
        --> symlink/copy vocab into rundir
        --> iterate over dc and do w.r.t vocab
        --> write out docwords.txt

 - Run topic model:  tm.learn(method=ldalib.NewmanGibbs)
        --> output will get stored in rundir ...





Keeping it simple
=================

It would be best to package the LDA funcitons and wrappers as the liblda,
but it is important to have an application in mind. The best candidate
for this right now is "autotagging" with the following intended workflow:

First run:

    1/  Developer prepares an instance of LDADocument and LDADocumentColleciton
        which have an api in style get_document, get_documents etc.
    2/  Automatically extract the Vocabulary OR offer a way to input your own LDAVocabulary class
    3/  Runs LDA (hyperparameters choice)
        store PHI, THETA on the filesystem for later reuse
    4/  Present results in a web form and ask for short description of each topic
        allow multiple short descr
        voting?
        special reject buttons: "topic is too broad", "topic is too narrow"
    5/  Output informaiton -- ex. back into a db, as filesystem attributes or something
        ex1: back into db for a wordpress blog
        ex2: django.contrib.tagging
        ex3: mac os extended attributes for files, symlinks into categories?

Subsequent runs:

    1/  Generate the Phi_~m for the new documents
    2/  Tag em

How do I benefit from this?
Create a repository where people can upload their Phi's ?
Then use some sort of aggregation?
Offer autotaggin service?





Subcategories
=============

This would be the golden dream.
    I(ti*tj , Ti)
    approximation
    subtopics




Hyperparameters
===============

What is the importance of \alpha \beta ?




Possible application
====================

inspired by ~/Desktop/.cleanup.sh 
goes through the entire list of documents not he desktop and
moves them into neat columns -- one column per topic
(live word counts? it is an inherently slow background process..)

new saved items on the desktop usually show up at the right (in Mac OS X)
so if the auto-placed columns for each topic are at the far left
it will  be very good…. the user will be happy to see his jumble of new
saved files file up nicely in rank based on the subjects he has been researching...

test -- how well can we classify…
if works ASK FOR HELP for the implementations
see: my question on stackoverflow 




if you re-arrange the icons a bit it understands what you mean 
and updates its internal notion of clusters

this way your desktop always stays organized
killer app 

which desktop env. can make this happen ?
do i have to learn Objective-C ?







TODO:
=====

Write the liblda
decide on an api
create class arXivDocument( LDADocument )
2-3 days of infrastructure building
try out class wikipediaDocument( LDADocument )





